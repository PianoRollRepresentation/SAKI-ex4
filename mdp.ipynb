{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "from mdptoolbox import mdp\n",
    "from itertools import product\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I. Data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "# data\n",
    "field_content = ['empty', 'white', 'blue', 'red']\n",
    "task = ['store', 'restore']\n",
    "item = ['white', 'blue', 'red']\n",
    "\n",
    "\"\"\"\n",
    "an action represents a field to store/restore an item on. The indices are arranged in the following way:\n",
    "\n",
    "                         [2 3]\n",
    "<store/restore-start> -> [0 1]\n",
    "\"\"\"\n",
    "actions = [0, 1, 2, 3]\n",
    "\n",
    "\"\"\"\n",
    "2x2 warehouse with reward/distance at every position:\n",
    "\n",
    "                         [3/4 1/6]\n",
    "<store/restore-start> -> [5/2 3/4]\n",
    "\"\"\"\n",
    "rewards_dict = {0: 3, 1: 2, 2: 2, 3: 1}\n",
    "dist_dict = {0: 2, 1: 4, 2: 4, 3: 6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'store_white': 0.12596306713953773, 'store_blue': 0.12168276874159227, 'store_red': 0.25241531123884065, 'restore_white': 0.12584077289959644, 'restore_blue': 0.12168276874159227, 'restore_red': 0.25241531123884065}\n"
     ]
    }
   ],
   "source": [
    "def probabilities_from_data() -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the relative frequencies of every task/item combination of trainingdata.txt.\n",
    "    \"\"\"\n",
    "\n",
    "    # read in data\n",
    "    f = open('warehousetraining.txt', 'r')\n",
    "\n",
    "    # convert every line to [<task>, <item>] array and store in color_and_tasks.\n",
    "    color_and_tasks = []\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        color_and_tasks.append(line.split())\n",
    "        line = f.readline()\n",
    "\n",
    "    total_length = len(color_and_tasks)\n",
    "\n",
    "    # compute relative frequencies.\n",
    "    p_store_white = len([cur for cur in color_and_tasks if cur == ['store', 'white']]) / total_length\n",
    "    p_store_blue = len([cur for cur in color_and_tasks if cur == ['store', 'blue']]) / total_length\n",
    "    p_store_red = len([cur for cur in color_and_tasks if cur == ['store', 'red']]) / total_length\n",
    "    p_restore_white = len([cur for cur in color_and_tasks if cur == ['restore', 'white']]) / total_length\n",
    "    p_restore_blue = len([cur for cur in color_and_tasks if cur == ['restore', 'blue']]) / total_length\n",
    "    p_restore_red = len([cur for cur in color_and_tasks if cur == ['restore', 'red']]) / total_length\n",
    "\n",
    "    # check if relative frequencies sum up to 1.\n",
    "    np.testing.assert_almost_equal(\n",
    "        p_store_white + p_store_blue + p_store_red + p_restore_white + p_restore_blue + p_restore_red,\n",
    "        1)\n",
    "\n",
    "    # store in dictionary.\n",
    "    return {'store_white': p_store_white,\n",
    "            'store_blue': p_store_blue,\n",
    "            'store_red': p_store_red,\n",
    "            'restore_white': p_restore_white,\n",
    "            'restore_blue': p_restore_blue,\n",
    "            'restore_red': p_restore_red}\n",
    "\n",
    "\n",
    "probs = probabilities_from_data()\n",
    "print(probs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def get_states() -> List[str]:\n",
    "    \"\"\"\n",
    "    Computes and returns the states. A state has the form\n",
    "\n",
    "    [<field_content>[0], <field_content>[1], <field_content>[2], <field_content>[3], <task>, <item>]\n",
    "\n",
    "    and represents an <item> to be stored/restored (represented by <task>) in the warehouse\n",
    "\n",
    "    [<field_content>[2] <field_content>[3]]\n",
    "    [<field_content>[0] <field_content>[1]].\n",
    "    \"\"\"\n",
    "    return list(product(field_content, field_content, field_content, field_content, task, item))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('empty', 'empty', 'empty', 'empty', 'store', 'white'), ('empty', 'empty', 'empty', 'empty', 'store', 'blue'), ('empty', 'empty', 'empty', 'empty', 'store', 'red'), ('empty', 'empty', 'empty', 'empty', 'restore', 'white'), ('empty', 'empty', 'empty', 'empty', 'restore', 'blue'), ('empty', 'empty', 'empty', 'empty', 'restore', 'red'), ('empty', 'empty', 'empty', 'white', 'store', 'white'), ('empty', 'empty', 'empty', 'white', 'store', 'blue'), ('empty', 'empty', 'empty', 'white', 'store', 'red'), ('empty', 'empty', 'empty', 'white', 'restore', 'white')]\n"
     ]
    }
   ],
   "source": [
    "states = get_states()\n",
    "print(states[:10])\n",
    "\n",
    "num_states = len(states)\n",
    "\n",
    "# check if all elements are unique.\n",
    "np.testing.assert_equal(len(list(set(states))), num_states)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Transition and Reward matrix computation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "def field_content_equals(from_state: list, to_state: list) -> bool:\n",
    "    \"\"\"\n",
    "    Indicates whether the field_content part of the from_state and the to_state\n",
    "    are the same.\n",
    "    \"\"\"\n",
    "    return from_state[:4] == to_state[:4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "def transition_prob(action: int, from_state: list, to_state: list) -> float:\n",
    "    \"\"\"\n",
    "    Computes the transition probability between a from_state and a to_state executing\n",
    "    an action.\n",
    "\n",
    "    :param action: the action to be executed (lies in [0, 1, 2, 3])\n",
    "    :param from_state: from-state of the transition\n",
    "    :param to_state: to-state of the transition\n",
    "    :return: Transition probability\n",
    "    \"\"\"\n",
    "\n",
    "    # get a list version of the from_state to compare it later with the to_state.\n",
    "    copy_from_state = list(from_state)\n",
    "\n",
    "    # grab the item part of the to_state.\n",
    "    to_item = to_state[-1]\n",
    "\n",
    "    # grab the task part of the to_state.\n",
    "    to_task = to_state[4]\n",
    "\n",
    "    if copy_from_state[4] == 'store':\n",
    "        # if this transition is not valid (warehouse location occupied)\n",
    "        if copy_from_state[action] != 'empty':\n",
    "            # agent stays in the from_state -> probability = 1\n",
    "            return 1 if from_state == to_state else 0\n",
    "\n",
    "        # if the applied action results in the to_state, return probability for that\n",
    "        copy_from_state[action] = copy_from_state[-1]\n",
    "        return probs[to_task + '_' + to_item] if field_content_equals(copy_from_state, list(to_state)) else 0\n",
    "    elif copy_from_state[4] == 'restore':\n",
    "        # if this transition is not valid (warehouse location is empty)\n",
    "        if copy_from_state[action] != copy_from_state[-1]:\n",
    "            # agent stays in the from_state -> probability = 1\n",
    "            return 1 if from_state == to_state else 0\n",
    "\n",
    "        # if the applied action results in the to_state, return probability for that\n",
    "        copy_from_state[action] = 'empty'\n",
    "        return probs[to_task + '_' + to_item] if field_content_equals(copy_from_state, list(to_state)) else 0\n",
    "\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "# test transition probabilities\n",
    "\n",
    "test_prob_impossible_restore_stay = transition_prob(0, ['empty', 'empty', 'empty', 'empty', 'restore', 'red'],\n",
    "                                                    ['empty', 'empty', 'empty', 'empty', 'restore', 'red'])\n",
    "\n",
    "np.testing.assert_equal(test_prob_impossible_restore_stay, 1)\n",
    "\n",
    "test_prob_impossible_store_no_stay = transition_prob(0, ['blue', 'empty', 'empty', 'empty', 'restore', 'red'],\n",
    "                                                     ['blue', 'red', 'empty', 'empty', 'restore', 'red'])\n",
    "\n",
    "np.testing.assert_equal(test_prob_impossible_store_no_stay, 0)\n",
    "\n",
    "test_prob_possible_store = transition_prob(1, ['blue', 'empty', 'empty', 'empty', 'store', 'red'],\n",
    "                                           ['blue', 'red', 'empty', 'empty', 'store', 'blue'])\n",
    "\n",
    "np.testing.assert_equal(test_prob_possible_store, probs['store_blue'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "def reward(action: int, state: List[str]) -> float:\n",
    "    if state[4] == 'store':\n",
    "        if state[action] != 'empty':\n",
    "            return rewards_dict[action]\n",
    "    elif state[4] == 'restore':\n",
    "        if state[action] != state[-1]:\n",
    "            return rewards_dict[action]\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "def transition_and_reward_matrix():\n",
    "    \"\"\"\n",
    "    Computes the transition matrix as a scipy.sparse.csr_matrix and the reward matrix.\n",
    "\n",
    "    :return: transition and reward matrix\n",
    "    \"\"\"\n",
    "    transitions = []\n",
    "    rewards = []\n",
    "\n",
    "    # compute the transition matrix and reward vector for every action.\n",
    "    for action in actions:\n",
    "        row = []\n",
    "        col = []\n",
    "        data = []\n",
    "\n",
    "        reward_vector = []\n",
    "\n",
    "        # compute the transition probability between every state and append it to transitions.\n",
    "        for id_from, from_state in enumerate(states):\n",
    "            for id_to, to_state in enumerate(states):\n",
    "                p = transition_prob(action, from_state, to_state)\n",
    "\n",
    "                if p > 0:\n",
    "                    row.append(id_from)\n",
    "                    col.append(id_to)\n",
    "                    data.append(p)\n",
    "\n",
    "            # append the reward of every state to rewards.\n",
    "            reward_vector.append(reward(action, from_state))\n",
    "\n",
    "        transitions.append(csr_matrix((data, (row, col)), shape=(num_states, num_states)))\n",
    "        rewards.append(reward_vector)\n",
    "\n",
    "    # transpose rewards since the mdptoolbox expects a (S, A) reward matrix\n",
    "    return transitions, np.array(rewards).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "P, R = transition_and_reward_matrix()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0].toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, 0],\n       [0, 0, 0, 0],\n       [0, 0, 0, 0],\n       ...,\n       [3, 2, 2, 1],\n       [3, 2, 2, 1],\n       [0, 0, 0, 0]])"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "# test if transition matrices are stochastic matrices.\n",
    "ones = np.zeros((4, num_states))\n",
    "for i, m in enumerate(P):\n",
    "    ones[i] = np.sum(np.array(m.toarray()), axis=1)\n",
    "\n",
    "np.testing.assert_array_almost_equal(ones, np.ones_like(ones))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "# test if shape of reward matrix is correct.\n",
    "np.testing.assert_array_equal(R.shape, (num_states, 4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## III. Computation of the optimal policy\n",
    "For the computation of the optimal policy, we use the policy iteration and the\n",
    "value iteration algorithm with discounts 0.3, 0.6, 0.9 and 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "algorithms = [mdp.PolicyIteration, mdp.ValueIteration]\n",
    "discounts = [0.3, 0.6, 0.9, 1]\n",
    "\n",
    "alg_discount_policies = []\n",
    "for alg in algorithms:\n",
    "    for d in discounts:\n",
    "        pi = alg(P, R, d)\n",
    "        pi.run()\n",
    "\n",
    "        alg_discount_policies.append({'algorithm': alg, 'discount': d, 'policy': pi.policy})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IV. Result Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def next_comb_mdp(cur_state: List, state_index: int, policy: tuple) -> List:\n",
    "    \"\"\"\n",
    "    Computes the next field_content part starting in the cur_state and following the policy.\n",
    "\n",
    "    :param cur_state: the previous state.\n",
    "    :param state_index: index in states of cur_state. Used to find the value in policy.\n",
    "    :param policy: the policy to be followed.\n",
    "    :return: field_content part as List.\n",
    "    \"\"\"\n",
    "\n",
    "    action = policy[state_index]\n",
    "    result = cur_state[:4]\n",
    "    cur_task = cur_state[4]\n",
    "    cur_item = cur_state[-1]\n",
    "\n",
    "    if cur_task == 'store':\n",
    "        result[action] = cur_item\n",
    "    elif cur_task == 'restore':\n",
    "        result[action] = 'empty'\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "def distance_mdp(warehouse_input: List[tuple], policy: tuple) -> float:\n",
    "    \"\"\"\n",
    "    Computes the distance the robot goes, given the warehouse_input and following the policy.\n",
    "\n",
    "    :param warehouse_input: List of task/item combinations that are coming to the warehouse.\n",
    "    :param policy: the policy to be followed.\n",
    "    :return: total distance the robot goes.\n",
    "    \"\"\"\n",
    "\n",
    "    # start with empty warehouse\n",
    "    cur_comb = ['empty', 'empty', 'empty', 'empty']\n",
    "    total_dist = 0\n",
    "\n",
    "    # work off the warehouse_input\n",
    "    for cur_task, cur_item in warehouse_input:\n",
    "        cur_comb.append(cur_task)\n",
    "        cur_comb.append(cur_item)\n",
    "\n",
    "        # find transition index for policy\n",
    "        state_index = states.index(tuple(cur_comb))\n",
    "\n",
    "        # compute next field_content part and add distance to total_dist\n",
    "        cur_comb = next_comb_mdp(cur_comb, state_index, policy)\n",
    "        total_dist += dist_dict[policy[state_index]]\n",
    "\n",
    "    return total_dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We compare our results with a greedy approach. For this approach, the robot always chooses the location where the item,\n",
    "which has to be stored/restored, as the valid position (store/restore task with item is valid) with the smallest distance from the\n",
    "start location."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "def next_comb_greedy(cur_state: List) -> List:\n",
    "    \"\"\"\n",
    "    Computes the next field_content part starting in the cur_state following a greedy approach.\n",
    "\n",
    "    :param cur_state: the previous state.\n",
    "    :return: field_content part as List.\n",
    "    \"\"\"\n",
    "\n",
    "    result = cur_state[:4]\n",
    "    cur_task = cur_state[4]\n",
    "    cur_item = cur_state[-1]\n",
    "\n",
    "    if cur_task == 'store':\n",
    "        # find next empty field\n",
    "        for action, field in enumerate(result):\n",
    "            if field == 'empty':\n",
    "                result[action] = cur_item\n",
    "                return result, action\n",
    "\n",
    "    elif cur_task == 'restore':\n",
    "        # find next field with cur_item\n",
    "        for action, field in enumerate(result):\n",
    "            if field == cur_item:\n",
    "                result[action] = 'empty'\n",
    "                return result, action\n",
    "\n",
    "    return result, 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "def distance_greedy(warehouse_input: List[tuple]) -> float:\n",
    "    \"\"\"\n",
    "    Computes the distance the robot goes, given the warehouse_input and following a greedy approach.\n",
    "\n",
    "    :param warehouse_input: List of task/item combinations that are coming to the warehouse.\n",
    "    :return: total distance the robot goes.\n",
    "    \"\"\"\n",
    "\n",
    "    # start with empty warehouse\n",
    "    cur_comb = ['empty', 'empty', 'empty', 'empty']\n",
    "    total_reward = 0\n",
    "\n",
    "    # work off the warehouse_input\n",
    "    for cur_task, cur_item in warehouse_input:\n",
    "        cur_comb.append(cur_task)\n",
    "        cur_comb.append(cur_item)\n",
    "\n",
    "        # compute next field_content part and add distance to total_dist\n",
    "        cur_comb, action = next_comb_greedy(cur_comb)\n",
    "        total_reward += dist_dict[action]  # action in [0, 1, 2, 3]\n",
    "\n",
    "    return total_reward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('store', 'red'), ('store', 'white'), ('restore', 'white'), ('store', 'red'), ('store', 'blue'), ('store', 'red'), ('restore', 'red'), ('restore', 'red'), ('restore', 'red'), ('store', 'red'), ('restore', 'blue'), ('restore', 'red'), ('store', 'blue'), ('restore', 'blue'), ('store', 'red'), ('store', 'red'), ('store', 'blue'), ('restore', 'blue'), ('restore', 'red'), ('store', 'red'), ('store', 'blue'), ('restore', 'blue'), ('restore', 'red'), ('store', 'blue'), ('store', 'white'), ('store', 'red'), ('restore', 'red'), ('restore', 'red'), ('restore', 'blue'), ('store', 'red'), ('restore', 'red'), ('store', 'white'), ('store', 'red'), ('store', 'red'), ('restore', 'red'), ('store', 'red'), ('restore', 'red'), ('restore', 'red'), ('restore', 'white'), ('restore', 'white'), ('store', 'blue'), ('store', 'white'), ('store', 'blue'), ('restore', 'white'), ('restore', 'blue'), ('restore', 'blue'), ('store', 'white'), ('store', 'red'), ('store', 'red'), ('store', 'red'), ('restore', 'red'), ('restore', 'white'), ('restore', 'red'), ('restore', 'red'), ('store', 'white'), ('restore', 'white'), ('store', 'white'), ('store', 'white'), ('store', 'blue'), ('store', 'white'), ('restore', 'blue'), ('restore', 'white'), ('restore', 'white'), ('store', 'white'), ('store', 'red')]\n"
     ]
    }
   ],
   "source": [
    "def data_to_warehouse_input() -> List[tuple]:\n",
    "    \"\"\"\n",
    "    Reads the warehouse input from testingdata.txt and stores it into task/item combinations.\n",
    "    :return: List of task/item combinations.\n",
    "    \"\"\"\n",
    "    f = open('warehouseorder.txt', 'r')\n",
    "\n",
    "    result = []\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        result.append(tuple(line.split()))\n",
    "        line = f.readline()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "w_input = data_to_warehouse_input()\n",
    "print(w_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm:  <class 'mdptoolbox.mdp.PolicyIteration'> , discount:  0.3 , distance:  160\n",
      "algorithm:  <class 'mdptoolbox.mdp.PolicyIteration'> , discount:  0.6 , distance:  160\n",
      "algorithm:  <class 'mdptoolbox.mdp.PolicyIteration'> , discount:  0.9 , distance:  130\n",
      "algorithm:  <class 'mdptoolbox.mdp.ValueIteration'> , discount:  0.3 , distance:  160\n",
      "algorithm:  <class 'mdptoolbox.mdp.ValueIteration'> , discount:  0.6 , distance:  160\n",
      "algorithm:  <class 'mdptoolbox.mdp.ValueIteration'> , discount:  0.9 , distance:  130\n",
      "greedy approach distance:  228\n"
     ]
    }
   ],
   "source": [
    "for res in alg_discount_policies:\n",
    "    print('algorithm: ', res['algorithm'], ', discount: ', res['discount'], ', distance: ',\n",
    "          distance_mdp(w_input, res['policy']))\n",
    "\n",
    "print('greedy approach distance: ', distance_greedy(w_input))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}